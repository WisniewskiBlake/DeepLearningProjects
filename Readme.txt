Collection of neural networks I have built to solve various problems. This repository uses Anaconda, Spyder, NumPy, Tensorflow, Keras, Jupyter, and Pandas. Churn_Modeling.csv is the dataset used to train my Artificial Neural Network. The dataset used to train my Convolutional Neural Network is 10,000 images of cats and dogs taken from the Kaggle website. 

The ANN (Artificial Neural Network) takes data from 10,000 bank customers that includes location, age, name, credit score, gender, balance, and tenure. From these variables, I train the ANN to figure out what is causing customers to leave. First, the data is broken up into independant and dependant variables. All catagorical data such as gender and location are converted into 0s and 1s. The data is then seperated into a training set and a test set. The training set is 8,000 observations, and the performance will be tested on 2,000 observations. I begin initializing my DeepLearning model by defining it as a sequence of layers. I name the neural network "classifier" as this is a classification problem and assign it to an object of the Sequential class. After this I use the Dense function to randomly initialise weights of variables to small numbers close to 0. I do this for each of the hidden layers. Forward-propogation is then used to assign weights to each variable; a predicted value is then generated. I compare the predicted value to actual value and measure the error generated. The error measured is back-propogated and weights are updated. I use Reinforcement Learning opposed to Batch Learning and update the weights after each observation. Once this is completed an epoch is created. I then redo the process to create more epochs.

The CNN (Concolutional Neural Network) takes images from Kaggle of 5,000 cats and 5,000 dogs from a superset of 25,000 images and sets out to recognize a cat from a dog. Here, the dataset is separated into two folders: the training set and the test set. This is because I needed to be able to specify to the algorithm a dependant variable to which to compare the predicted value generated from the CNN. The training set contains 8,000 images and the test set contains 2,000 images. My CNN is a sequence of layers, therefore I used the Sequential package to initialize it. Convolution2D is imported to add the convolutional layers in the first step. MaxPooling2D is used in the pooling step to add the pooling layers. Flatten is imported in the flattening step where I convert all the pooled feature maps that I created through convolution and max pooling into a large feature vector that then becomes the input of the fully connected layers. Dense is used to add the fully connected layers like a classic ANN. I first name my CNN "classifier" because it is going to classify images, then assign it to Sequential which creates an object of the Sequential class. Next, I add the convolutional layers. This is where the images are converted into a table of pixel values by applying feature detectors to each image which produces a feature map. Many feature maps creates a convolutional layer.
